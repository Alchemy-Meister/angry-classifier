% !TeX root = repressed-anger.tex

\section{Previous Work}
\label{sec:previous_work}

The study of anger and its management has been studied since ancient times. According to \acrfull{apa}, anger is ``an emotion characterized by antagonism toward someone or something you feel has deliberately done you wrong'' \cite{angerAPA}. Anger is a normal emotion all human experience. Modern psychologists have studied the health effects that may derivate from anger suppression, such as shown in \cite{kemp1995anger} and \cite{staicu2010anger}, linking it to a more extremist and sarcastic personality. This research aims to find the answer to the question: ``Can the repressed anger be detected in text?''. Based on the definition of personality of a subject that has experienced repressed anger, the problem formulation has been simplified into finding negative messages influenced by anger that covered by a layer of sarcasm. The following subsections present a brief summary of the research conducted in the detection of anger and sarcasm.

\subsection{Anger}
\label{subsec:anger}

As explained in section \ref{sec:emotion_detection}, the increase of the usage of social media and computational viability to process all the publicly available data has enable the detection of emotions from text. However as there is not literature that focuses on anger emotion, this section will briefly enunciate the approaches researched to classify emotions that contain anger as target label.

In 2007 during international workshop of evaluations of computational semantics analysis system, known as SemEval \cite{SemEvalPortal}, presented an task that analyzed the affective text, in which the participants had to calculate the the valence and emotional class of news titles. Three groups participated in the emotion classification subtask: SWAT, UA and UPAR7. 

The system proposed by SWAT was based on unigram trained model supervised learning. In addition to the emotion label target given this group perform a synonym expansion of these keywords by using the Roget Thesaurus. The training of the system was performed by combining the development data provided by the SemEval task organizers plus a set of 1000 headlines that was annotated from the group.

UPAR7 developed a linguistic rule-based system approach. The first step was to pre-process the data by un-capitalize the common words. Then, each word was rated separately with each emotion target label. 

In order to determine the type of emotion in the headline UA group collected statistics from three web search engines to calculate the distribution of nouns, verbs, adjectives and adverbs of the headline. The emotion scores were obtained through \acrfull{pmi}.

The F1-score obtained by SWAT, UA and UPAR7 for anger sentiment was 7.06, 16.03 and 3.02 respectively (results multiplied by 100) \cite{strapparava2007semeval}.

Authors in \cite{strapparava2008learning} implemented five system for emotion analysis based on a knowledge based emotion annotation and corpus based emotion annotation: \acrshort{wn}-affect presence, \acrshort{lsa} single word, \acrshort{lsa} emotion synset, \acrshort{lsa} all emotion words and \acrshort{nb} trained on blogs. For anger annotation, the proposed system scored a F1 score of 16.77 (results multiplied by 100), outperforming the system proposed by UA in SemEval for anger annotation.

Kirk Roberts et al. developed a system composed of six \acrshort{svm} classifiers, one for each Ekman's sentiment basic emotion. The Features selected as input for the binary classifier where: unigrams, bigrams, trigrams, presence of interrogation or exclamation mark, \acrlong{wn} synsets, \acrshort{wn} hypernyms, \acrlong{lda} topic scores and high \acrshort{pmi} unigrams (significant words). The anger classifier used unigrams, synsets, topis and significant words, scoring a F1 score of 0.642 \cite{roberts2012empatweet}.

Chew-Yean Yam posted at Microsoft developer Blog an example of emotion classification using Deep Learning techniques. The corpus was collected by using Amazon's Mechanical Turk to perform a \acrfull{hit} to manually annotate the data, obtaining a total of 784,349 samples of informal short English messages classified as five classes, anger, sadness, fear, happiness and excitement. The Deep Learning architecture is described ad a \acrfull{nn} with five out nodes, three hidden layers, that contain 5, 25 and 125 nodes respectively. The loss function selected was Cross entropy with a stochastic gradient descent optimization algorithm. The learning rate was set to 0.001. The maximum training iteration was set to 100 with a greedy pre-trainer type executed though-out 25 epochs. The anger classifier in this system obtained a F1 score of 0.64958 \cite{microsoftEmotionAPI}.



\subsection{Irony and Sarcasm}
\label{subsec:irony_sarcasm}

Defend the idea of using irony and sarcasm as the same, since sarcasm is a subset of irony.
``In linguistics, verbal irony is sometimes used as a synonym of sarcasm \cite{giora2013negation}; \cite{giora2015defaultness} and \cite{giora2015default}. According to the literature, boundaries in meaning between irony, sarcasm et similia are fuzzy \cite{bosco2013developing}. While some authors consider irony as an umbrella term covering also sarcasm \cite{gibbs1991psychological}, \cite{wilson2006pragmatics} and \cite{kreuz1993empirical}, others provide insights for a separation \cite{filatova2012irony}.''


Survey of the approaches used to detect sarcasm. Three approaches, rule-based, statistical approaches, learning approaches. Inside Learning approaches there are architectures based on deep learning \cite{joshi2016automatic}.

Detection of Portuguese irony using pattern matching rules such as diminutive forms, interjections, verb morphology, heavy punctuation, quotation marks, laughter expressions, among others. Classifying the sentences as ironic, not ironic, undecided and ambiguous. They concluded stating that the best patters for irony recognition are quote and laugh obtaining a precision of 68.29\% and 85.40\% respectively \cite{carvalho2009clues}.

Semi-supervised techniques for sarcastic sentences in Twitter and Amazon, 5.9 million unique tweets, use of \#sarcasm hashtag, removal of link, users and hashtags, pattern extraction, such as \acrfullpl{hfw}, \acrfullpl{cw}, punctuation based features to create single entry feature vectors. classification range of 1 to 5 to measure the presence of sarcasm, with a \acrfull{knn}-like strategy \cite{davidov2010enhanced}. Evaluation using 5-fold cross validation using all the features obtained the highest F-score of 0.545 on Twitter and 0.827 in Amazon \cite{davidov2010semi}.